{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ac1f236",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.data.data_collator because of the following error (look up to see its traceback):\n[WinError 182] The operating system cannot run %1. Error loading \"C:\\Users\\anand\\anaconda3\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglue_compute_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxnli_compute_metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m from .processors import (\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mDataProcessor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\data\\processors\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mglue\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglue_convert_examples_to_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglue_output_modes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglue_processors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglue_tasks_num_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msquad\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSquadExample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSquadFeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSquadV1Processor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSquadV2Processor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquad_convert_examples_to_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataProcessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInputExample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInputFeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSingleSentenceClassificationProcessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\data\\processors\\squad.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    123\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf' Error loading \"{dll}\" or one of its dependencies.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 182] The operating system cannot run %1. Error loading \"C:\\Users\\anand\\anaconda3\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28880\\2242651474.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mDataCollatorForLanguageModeling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTrainingArguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDistilBertConfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDistilBertForMaskedLM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDistilBertTokenizerFast\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.data.data_collator because of the following error (look up to see its traceback):\n[WinError 182] The operating system cannot run %1. Error loading \"C:\\Users\\anand\\anaconda3\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import transformers\n",
    "import tokenizers\n",
    "import datasets\n",
    "\n",
    "from transformers import (DataCollatorForLanguageModeling, Trainer,TrainingArguments, DistilBertConfig, DistilBertForMaskedLM, DistilBertTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6623a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizers.BertWordPieceTokenizer(strip_accents=False)\n",
    "\n",
    "#no training file yet still looking\n",
    "\n",
    "tokenizer.train(pdf, vocab_size=5000)\n",
    "\n",
    "tokenizer.save_model('tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fcda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertConfig, DistilBertForMaskedLM\n",
    "\n",
    "\n",
    "config = DistilBertConfig(vocab_size=30000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68f3d520",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1934984032.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\anand\\AppData\\Local\\Temp\\ipykernel_28880\\1934984032.py\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    return_special_tokens_mask=True,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#helper function singh ji \n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"/content/Tokenizer\", do_lower_case=False)\n",
    "\n",
    "\n",
    "#dont have any file to train on yet so is a place holder\n",
    "def get_tokenized_dataset():\n",
    "  data_files = {\"train\": \"/content/Train.txt\"}\n",
    "  tokenized_datasets = datasets.load_dataset('text', data_files=data_files)\n",
    "    \n",
    "    \n",
    "def tokenize_function(examples):\n",
    "    # Remove the empty lines\n",
    "    examples[\"text\"] = [line for line in examples[\"text\"] if len(line) > 0 and not line.isspace()]\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"do_not_pad\",\n",
    "        truncation=\"do_not_truncate\"\n",
    "        return_special_tokens_mask=True,\n",
    "    )\n",
    "\n",
    "    return tokenized_datasets.with_transform(tokenize_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_collator():\n",
    "  return DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e4462",
   "metadata": {},
   "outputs": [],
   "source": [
    " args = TrainingArguments(output_dir=\"/content/Checkpoints\", do_train=True, per_device_train_batch_size=32,weight_decay=0.01, \n",
    "                    num_train_epochs=3, save_total_limit=2, save_steps=500,\n",
    "                    disable_tqdm=False, remove_unused_columns=False, ignore_data_skip=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d959dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "       model=model,\n",
    "       args=args,\n",
    "       train_dataset=tokenized_datasets[\"train\"],\n",
    "       tokenizer=tokenizer,\n",
    "       data_collator=data_collator,\n",
    "   )\n",
    "   trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
